
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Build Hadoop Native Librairies - Blog dealing about Data</title>
  <meta name="author" content="Romain NIO">

  
  <meta name="description" content="The Hadoop native librairies are compiled for 32 bits plateforms. If you are using Hadoop on x64, you have probably been faced to the following issue &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.rnio.me/blog/2015/06/16/build-hadoop-native-librairies/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Blog dealing about Data" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Blog dealing about Data</a></h1>
  
    <h2>Romain NIO  - Data team Oscaro.com</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="www.rnio.me">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Build Hadoop Native Librairies</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-06-16T19:21:41+02:00'><span class='date'><span class='date-month'>Jun</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>7:21 pm</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><p>The Hadoop native librairies are compiled for 32 bits plateforms. If you are using Hadoop on x64, you have probably been faced to the following issue :</p>

<pre><code> WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 
</code></pre>

<p>For performances purposes, it better to recompile those libraries according to your plateform.</p>

<p>It’s a good idea to compile on the same architecture than your Hadoop production plateform. Of course, avoid any compilations on your production server Not sure that hadoop native librairies are compiled for 32 bits plateform ? You can check that with the following command :</p>

<pre><code>file $HADOOP_HOME/lib/native/libhadoop.so.1.0.0
</code></pre>

<p>Here the result :</p>

<pre><code>file libhadoop.so.1.0.0: ELF 32-bit
</code></pre>

<h2 id="download-source">Download Source</h2>

<p>Visit http://mirrors.ircam.fr/pub/apache/hadoop/common/ and find the tarball of your Hadoop version. Download it :</p>

<pre><code>wget http://mirrors.ircam.fr/pub/apache/hadoop/common/hadoop-2.4.1/hadoop-2.4.1.tar.gz
</code></pre>

<p>Install dependencies :</p>

<pre><code>sudo apt-get install cmake autoconf automake libtool gcc zlib1g-dev pkg-config libssl-dev openssl gcc g++ make maven zlib zlib1g-dev libcurl4-o
</code></pre>

<p>Install protobuf :</p>

<pre><code>wget https://protobuf.googlecode.com/files/protobuf-2.5.0.tar.gz gunzip protobuf-2.5.0.tar.gz
tar -xvf protobuf-2.5.0.tar
cd protobuf-2.5.0
sudo ./configure --prefix=/usr sudo make
sudo make install
</code></pre>

<h2 id="compile-hadoop">Compile Hadoop</h2>
<p>Unzip you tarball :</p>

<pre><code>tar -xzf hadoop-2.4.1-src.tar.gz
</code></pre>

<p>Enter in your folder :</p>

<pre><code>cd hadoop-2.4.1-src/
</code></pre>

<p>Set your environment :</p>

<pre><code>export Platform=x64
Compile :
mvn package -Pdist,native -DskipTests -Dtar
</code></pre>

<p>If you face issues while compiling, google is your friend ;). If all is OK, you will have this kind of output :</p>

<pre><code>[INFO] ------------------------------------------------------------- [INFO] BUILD SUCCESS
[I------------------------------------------------------------------ [INFO] Total time: 5:27.684s
[INFO] Finished at: Wed Jul 02 19:33:51 CEST 2014
[INFO] Final Memory: 165M/834M
[INFO] -----------------------------------------------------------------------
</code></pre>

<p>You can find the librairies in this folder :</p>

<pre><code>cd ./hadoop-dist/target/hadoop-2.4.1/lib/native
</code></pre>

<p>We can see all built librairies (“ls ­lh”) :</p>

<pre><code>-rw-r--r-- 1 hadoop hadoop 1.1M Jul 2 19:07 libhadoop.a
lrwxrwxrwx 1 hadoop hadoop 18 Jul 2 19:07 libhadoop.so -&gt; libhadoop.so.1.0.0 -rwxr-xr-x 1 hadoop hadoop 650K Jul 2 19:07 libhadoop.so.1.0.0
-rw-r--r-- 1 hadoop hadoop 1.4M Jul 2 19:07 libhadooppipes.a
-rw-r--r-- 1 hadoop hadoop 421K Jul 2 19:07 libhadooputils.a
-rw-r--r-- 1 hadoop hadoop 373K Jul 2 19:07 libhdfs.a
lrwxrwxrwx 1 hadoop hadoop 16 Jul 2 19:07 libhdfs.so -&gt; libhdfs.so.0.0.0 -rwxr-xr-x 1 hadoop hadoop 245K Jul 2 19:07 libhdfs.so.0.0.0
</code></pre>

<p>At this step, you can check the plateform of the librairies :</p>

<pre><code>file libhadoop.so.1.0.0
</code></pre>

<p>The result seems to be OK :</p>

<pre><code>libhadoop.so.1.0.0: ELF 64-bit LSB shared object, x86-64
</code></pre>

<p>save them and archive this package :</p>

<pre><code>tar -cvzf hadoop-native-libraries-2.4.1.tgz *
</code></pre>

<h2 id="copy-librairies-on-your-cluster">Copy librairies on your cluster</h2>

<p>This step need to be reproduced for namenode and datanode.
You just need to copy all those file in $HADOOP_HOME/lib/native (eg : /usr/local/hadoop/lib/native) :</p>

<pre><code>$ rsync hadoop-native-libraries-2.4.1.tgz &lt;your_hadoop_production_server&gt;:/usr/local/hadoop/lib/native/
</code></pre>

<p>Enter in your Hadoop home (eg : /usr/local/hadoop/lib/native)</p>

<pre><code>$ cd $HADOOP_HOME/lib/native
</code></pre>

<p>Extract archives :</p>

<pre><code>$ tar -xzf hadoop-native-libraries-2.4.1.tgz
</code></pre>

<h2 id="configure-your-environment">Configure your environment</h2>

<p>You probably have a specific unix user for your hadoop cluster. Add those lines in your ~/.bashrc (or coure, edit paths according to your configuration):</p>

<pre><code>export HADOOP_INSTALL=/usr/local/hadoop
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_COMMON_LIB_NATIVE_DIR $HADOOP_OPTS"
</code></pre>

<h2 id="stop-and-restart-hadoop">Stop and restart Hadoop</h2>

<p>Stop cluster :</p>

<pre><code>./stop-dfs.sh 
./stop-yarn.sh
</code></pre>

<p>Source again your bashrc :</p>

<pre><code>source ~/.bashrc
</code></pre>

<p>Start Hadoop :</p>

<pre><code>./start-dfs.sh
./start-yarn.sh
</code></pre>

<p>Test that the message disappears :</p>

<pre><code>$ hadoop fs -ls /user/hadoop
Found 1 item
-rwxr-xr-x 1 hadoop supergroup 8 2014-07-01 14:06 /user/hadoop/toto.txt
</code></pre>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Romain NIO</span></span>

      




<time class='entry-date' datetime='2015-06-16T19:21:41+02:00'><span class='date'><span class='date-month'>Jun</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>7:21 pm</span></time>
      


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://www.rnio.me/blog/2015/06/16/build-hadoop-native-librairies/" data-via="" data-counturl="http://www.rnio.me/blog/2015/06/16/build-hadoop-native-librairies/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/06/05/split-large-file-unix-in-bash-command-line/" title="Previous Post: Split large file in bash">&laquo; Split large file in bash</a>
      
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/06/16/build-hadoop-native-librairies/">Build Hadoop Native Librairies</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/05/split-large-file-unix-in-bash-command-line/">Split Large File in Bash</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Romain NIO -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
